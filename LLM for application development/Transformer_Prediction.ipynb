{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KkbS8MXf3krC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Simulate decoder output for a token (shape [512])\n",
        "decoder_output = torch.randn(512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVJ3oIGkI7Bm",
        "outputId": "f2709094-af67-4110-ef79-393e8ce59c16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.1057,  0.5291,  0.2447, -1.2045, -0.8594, -0.4572, -0.5634, -0.2186,\n",
              "        -0.3098, -0.4529,  0.2213,  1.0539,  0.2979,  1.1511, -0.9839,  0.5469,\n",
              "        -1.4479,  0.3466, -0.9221, -0.3963, -0.1579, -0.2697, -0.3826, -0.2695,\n",
              "         0.0939,  0.3532,  0.5796,  2.1373,  2.3235,  0.1988,  0.3462,  0.1488,\n",
              "         0.8079, -0.6490, -1.3221,  0.5943, -0.8413,  0.5728,  0.1371,  1.1208,\n",
              "        -0.6605,  0.0826,  0.1901,  0.2705, -0.1728, -0.6277,  0.2997,  1.8410,\n",
              "        -0.0967,  0.7971,  1.3536,  0.5894,  1.3186,  0.3903,  0.3851,  1.8806,\n",
              "         1.8441,  0.6573,  1.0535,  1.4509,  1.1745, -2.5048,  0.2047, -1.8911,\n",
              "         0.9565,  0.3608,  0.7415, -0.2830, -0.1244,  0.1392,  0.3397, -0.5342,\n",
              "         0.4806, -0.4807,  0.6702, -0.4142, -1.0479,  1.1767,  2.3256, -2.6124,\n",
              "        -0.3682,  0.0710,  0.2212,  1.1598,  0.4701, -1.3159, -0.3491,  0.6747,\n",
              "        -0.0984, -0.8873,  0.0843, -0.6613,  0.4843, -0.9173,  0.7706,  0.5812,\n",
              "         0.5483, -0.0816,  1.8819, -0.3514, -0.0285, -0.1061,  0.6668, -0.0228,\n",
              "         0.9588,  2.1593, -0.4871,  1.7347,  0.5314,  0.7905,  0.3225, -0.8906,\n",
              "        -0.3150,  1.0376,  0.1741,  0.7651, -1.2226, -1.0094, -1.3870,  1.4708,\n",
              "         0.3265,  1.2788, -0.3792, -0.3977,  0.1860,  0.2128, -0.6036,  0.0242,\n",
              "         0.4066,  1.2193,  0.9317,  0.4475, -0.2401,  1.0108, -0.1015, -1.1341,\n",
              "        -1.1039,  0.2841, -0.4112,  0.0074, -0.5755, -0.3680,  0.6670,  0.0714,\n",
              "         0.5760,  1.6273, -0.4209,  0.2715,  0.0678,  1.1388, -0.8820,  0.3647,\n",
              "        -0.7133, -0.8434,  1.5721,  0.0076, -1.3138,  0.2778,  1.2553, -0.0185,\n",
              "         2.8284, -0.0871,  1.2861, -2.3053,  1.2543,  0.6830, -1.6318, -1.3825,\n",
              "        -1.7608, -0.9161, -0.6902, -0.1948,  0.4277, -2.1606,  0.3860,  1.5177,\n",
              "        -0.4946, -0.8286, -1.1969,  0.0729, -1.1911,  0.9157, -0.9844,  2.4165,\n",
              "        -0.8106,  1.7026,  0.3591, -0.8454, -0.8690, -1.1936, -0.3670,  0.9512,\n",
              "         0.4965, -0.7167, -2.1283, -0.9006,  0.6921,  1.0018, -2.4841, -0.5889,\n",
              "         0.4497,  2.3538,  0.6218,  1.4340, -0.1611,  0.8386, -0.0835, -0.6247,\n",
              "         0.8510, -0.2339,  1.0248,  0.0058,  1.7048, -0.2098, -0.3386, -2.1567,\n",
              "        -0.4590, -0.1513, -0.3057,  2.0541,  1.3226, -0.4568,  0.5808,  0.9121,\n",
              "         0.6023, -1.5064, -0.8648, -0.9142, -0.9359,  0.4029,  0.7843,  1.7445,\n",
              "         0.0218,  0.7129,  1.0476,  0.5379, -0.4123, -0.4071, -1.0567, -0.6849,\n",
              "        -0.9165,  0.1187,  0.8722, -1.7425,  1.1710, -0.2249,  0.1959,  0.7351,\n",
              "         0.5290, -1.4796,  0.2304, -0.2245, -1.0591, -1.1794,  0.3892,  0.0319,\n",
              "         0.3106, -1.7876, -0.3364,  0.1079, -1.3013,  0.7406, -1.1310, -0.6988,\n",
              "         0.2045, -0.0955, -0.2488,  0.7430,  0.1658, -0.3345,  0.4749, -0.2369,\n",
              "         0.6797,  0.1960,  1.6193,  0.2495, -2.5055,  1.8497, -0.7183,  2.0995,\n",
              "        -0.8632, -0.3601, -0.2714, -1.7984, -0.3624, -0.9636,  0.4517,  0.2129,\n",
              "        -1.4749,  0.4730, -0.5657,  0.4426, -0.9078,  1.1503, -1.3511, -0.0990,\n",
              "        -2.0631,  0.1303,  0.2359, -0.0075, -1.2557, -1.4766,  0.5433,  0.2011,\n",
              "         0.8524, -0.7765,  0.4624,  0.2203, -1.8417, -0.1600, -1.1679, -1.1614,\n",
              "         0.6565, -1.4460,  0.0182,  0.5132, -0.2528, -0.3417,  0.0187, -0.3824,\n",
              "        -0.2963, -0.5177,  0.0802,  0.6747, -2.0351, -1.7710,  1.5395,  0.7032,\n",
              "        -1.0966, -0.9457,  1.3724, -0.5891, -2.7584,  1.2388,  0.1930,  0.7674,\n",
              "        -1.3830,  0.2396,  0.5066,  0.5268,  1.1007, -0.2196, -1.2513, -1.0037,\n",
              "         1.4738,  1.1704, -0.1987, -1.0544, -0.1322,  0.6411,  0.1380, -1.3859,\n",
              "        -0.0756, -2.3674,  1.2909, -0.0811,  2.5489, -0.3599, -0.5849, -0.7650,\n",
              "         0.2775,  0.6381, -0.9716,  0.2699, -0.2478,  1.3243, -0.4883, -1.0678,\n",
              "        -2.0237,  0.6957,  1.0110, -0.5717,  0.9532, -1.5796,  0.1678, -1.6460,\n",
              "        -0.6130,  1.4746,  2.0445,  0.8713, -0.3945,  1.6837, -0.7665,  0.8019,\n",
              "         0.8285, -0.0642,  0.1614, -0.3190,  0.0541, -0.1413,  1.3963,  0.2299,\n",
              "         0.4085,  0.3722,  0.0425, -1.4344, -0.0935, -0.6229, -0.4609, -1.0218,\n",
              "        -2.0608,  0.5796, -0.3564, -1.3407,  0.2852,  0.5877, -0.4095,  0.2114,\n",
              "         1.6738,  0.6748,  2.2739, -0.5908, -1.1476, -0.3232, -0.7087,  1.0432,\n",
              "         0.2218,  0.0367,  0.7675, -0.7755, -0.1832, -0.1247, -0.4377,  0.7463,\n",
              "         1.1231, -2.1017,  0.3134, -0.6278, -1.0786,  1.1017,  0.4286, -0.3526,\n",
              "         0.4654, -0.0399,  1.6045,  0.3135, -0.1862,  1.8089,  0.3322, -0.3428,\n",
              "         0.7245,  1.8880,  0.1743,  1.3121,  0.7297,  1.5863,  0.4414,  1.7152,\n",
              "         0.4216, -0.9545, -0.3907,  0.9185, -0.4973, -0.0078, -0.6276,  0.1997,\n",
              "        -1.1140,  0.5187,  0.8821,  1.4284, -1.0196, -0.5138, -1.1175, -1.3237,\n",
              "        -0.1924,  1.2700,  0.1469, -0.3025,  1.4004, -0.5135,  1.0081,  0.6519,\n",
              "        -0.4316,  0.3561,  0.9899, -0.3378,  1.2138,  0.5881,  1.2775, -1.2856,\n",
              "         1.0224, -0.6061,  2.4479,  0.8547, -0.0196, -1.5627, -1.0321, -0.5750,\n",
              "         0.5837, -0.1678, -1.5671, -1.2154, -0.2819, -0.8745,  0.0231, -0.2613,\n",
              "         0.2632,  0.3388, -1.6802,  0.9577,  0.1921,  0.1437, -0.5812,  0.6156,\n",
              "        -0.5198,  0.2838, -0.4159, -0.6737,  0.6844,  0.9381, -1.6802,  0.8483])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the linear layer that maps to vocabulary logits\n",
        "linear = nn.Linear(512, 10000)  # d_model=512, vocab_size=10000"
      ],
      "metadata": {
        "id": "jBj3BEeQ33q6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass through linear layer â†’ get logits (unnormalized scores)\n",
        "logits = linear(decoder_output)  # shape: [10000]"
      ],
      "metadata": {
        "id": "2VwEkCYg35Dv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSV_211qJOuA",
        "outputId": "d07428fc-e812-49d6-fc58-0e8a95a513ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7199, -0.3756,  0.0794,  ...,  0.9694,  0.5453,  0.1261],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply softmax to get probabilities\n",
        "probs = F.softmax(logits, dim=0)  # shape: [10000]\n",
        "\n",
        "# Use argmax to get predicted token ID\n",
        "predicted_token_id = torch.argmax(probs).item()\n",
        "\n",
        "print(f\"Predicted token ID: {predicted_token_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ_8EYbp374U",
        "outputId": "9bf680bf-3036-4c0b-d923-c83b7c376697"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted token ID: 8627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IL4JPumiJUVY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}