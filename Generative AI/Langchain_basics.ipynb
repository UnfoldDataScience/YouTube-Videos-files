{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "346d9d2c-9483-4655-9125-38dc41dbd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3102e197-cf44-45b4-98d5-80e896755136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .env file from local\n",
    "env_path = r'E:\\YTReusable\\.env'\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63af01cd-58fa-4f9a-8477-dd5e489bacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad41ae3-036d-4c2a-9405-aad0ae87c4a5",
   "metadata": {},
   "source": [
    "# 1- chains/Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d0fb4b0-e5f3-4efa-9eeb-22fb19ceb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4f6b280-0186-44f9-8d1c-81d658cadde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f2c45df-32c8-4f5f-a2e5-ab4d7c63341a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the cricket team bring a ladder to the game?  \\n\\nBecause they heard the match was going to be a high score!'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"cricket\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57006e19-eb64-46fb-95be-ab2e493c897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '8', '9']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable = RunnableLambda(lambda x: str(x))\n",
    "runnable.batch([7, 8, 9])\n",
    "\n",
    "# Async variant:\n",
    "# await runnable.abatch([7, 8, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e41bb1-ecae-46bb-97a1-395516b001c5",
   "metadata": {},
   "source": [
    "# 2 - Document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19843d4b-ac40-4223-9a90-106cbc96d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = (\n",
    "    \"C://Users//amanr//OneDrive//Desktop//Cricket.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e65751c7-2cb5-45fe-8cee-0e43f2452b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc1db9eb-6195-44c7-bf29-2dc2bd572526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'C://Users//amanr//OneDrive//Desktop//Cricket.pdf', 'page': 0}\n",
      "\n",
      "10\n",
      "ricket grew out of the many stick-and-\n",
      "ball games played in England 500 years\n",
      "ago. The word ‘bat’ is an old English word that\n",
      "simply means stick or club. By the seventeenth\n",
      "century, cricket had evolved enough to be\n",
      "recognisable as a distinct game. Till the middle of\n",
      "the eighteenth century, bats were roughly the same\n",
      "shape as hockey sticks, curving outwards at the\n",
      "bottom. There was a simple reason for this: the ball\n",
      "was bowled underarm, along the ground and the\n",
      "curve at the end of the bat gave the batsman the\n",
      "best chance of making contact.\n",
      "One of the peculiarities of cricket is that a\n",
      "Test match can go on for five days and still end\n",
      "C\n",
      "Before you read\n",
      "Sport is an integral part of a healthy life. It is one way in\n",
      "which we amuse ourselves, compete with each other and\n",
      "stay fit. Among the various sports such as hockey, football\n",
      "and tennis, cricket appears to be the most appealing\n",
      "national entertainment today. How much do we really\n",
      "know about the game called ‘cricket’?\n",
      "   The Story of\n",
      "   Cricket\n",
      "   I\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "—————–\n",
      "2022-23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a50151b-a450-4c76-a07a-11abced44274",
   "metadata": {},
   "source": [
    "# 3 - text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f6b76c5-9ed6-4543-b1ed-a589ab3b3db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Hello'\n",
      "page_content='This is'\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load example document\n",
    "with open(\"Aman.txt\") as f:\n",
    "    Aman = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=2,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "texts = text_splitter.create_documents([Aman])\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4a20a-0a3f-4e4b-b141-abba74643bf5",
   "metadata": {},
   "source": [
    "# 4 - store in chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21bf2ae6-fcf1-46ed-b045-556ca4cd511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader('Aman.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5460e43-a52a-4153-8899-0c572ff65846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "847e9f13-95c8-47e2-82d0-f01f2952ca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "This is Aman\n",
      "Welcome to UFDS\n"
     ]
    }
   ],
   "source": [
    "query = \"Welcome\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78598e-5695-4325-8626-aa4abe7fd8a8",
   "metadata": {},
   "source": [
    "# 5 - Memory and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3a8e317-60ed-4064-b9e0-17e0de5acd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-f64ce809-37e5-483b-8903-19a235ed2c19-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9999676a-3374-44fe-a7ca-c9bc68e51735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't know your name. If you'd like to share it, feel free!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-2c220115-824b-42d7-af65-f8c82557068c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 21, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f2b31e2-0d4d-41f9-8351-b9212953331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Bob! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 33, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-3689bf1c-9c58-4563-a6a1-0efef3b141b6-0', usage_metadata={'input_tokens': 33, 'output_tokens': 13, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c94fcf55-51c7-4357-9bb0-0c3983be8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5cad8da-0553-4cc2-9998-faa7e87bbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b20d97a-317b-43e4-a4e5-7866b213de52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "325a1a6d-5e2c-41dd-9c36-f151875bcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I am a data scientist\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb24e597-c81c-47ce-9615-96b94aeb9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What do I do?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b98a421-1e7f-4bd7-aaa4-a85ddb9cb619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As a data scientist, your responsibilities might include a variety of tasks, such as:\n",
      "\n",
      "1. **Data Collection and Cleaning**: Gathering data from various sources, ensuring its accuracy and completeness, and preprocessing it to make it usable for analysis.\n",
      "\n",
      "2. **Exploratory Data Analysis (EDA)**: Analyzing and visualizing data to uncover patterns, trends, and insights that can inform decision-making.\n",
      "\n",
      "3. **Statistical Analysis**: Applying statistical methods to analyze data and test hypotheses.\n",
      "\n",
      "4. **Machine Learning**: Developing, training, and deploying machine learning models to make predictions or automate decisions based on data.\n",
      "\n",
      "5. **Communication**: Presenting your findings to stakeholders through data visualizations, reports, or presentations to help inform business strategies.\n",
      "\n",
      "6. **Collaboration**: Working with other teams (like engineering, product management, and business) to understand their data needs and deliver impactful solutions.\n",
      "\n",
      "7. **Continuous Learning**: Staying updated with the latest tools, technologies, and methodologies in data science.\n",
      "\n",
      "Is there a specific aspect of your work or a project you're currently involved in that you'd like to discuss?\n"
     ]
    }
   ],
   "source": [
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efdc93-0a57-4a4f-93d8-1e88356452c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
