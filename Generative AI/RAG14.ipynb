{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef290dd7-812a-41d0-a1b6-f36627378592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83da8373-1435-4955-ad42-1644cdbf0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3eb218-9138-4195-b948-0cdee99b973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "env_path = r'E:\\YTReusable\\.env'\n",
    "load_dotenv(env_path)\n",
    "# Access variables from the .env file\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34269dc0-8e69-419f-93d1-9925275f4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "pinecone = Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1cf093-4375-4cd8-bffa-855b725a40f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or connect to Pinecone index\n",
    "index_name = 'rag-example8'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "   pinecone.create_index(name=index_name, dimension=1536, metric='cosine',spec=ServerlessSpec(cloud='aws', region='us-west-2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835d1285-735d-40c7-a2ce-96f17f2d6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "def0e4b6-47e3-4876-b1f4-31c49cd4d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data: A small set of documents or FAQs (can be imported easily)\n",
    "data = {\n",
    "    \"questions\": [\n",
    "        \"What is AI?\",\n",
    "        \"What is Pinecone?\",\n",
    "        \"How do embeddings work?\",\n",
    "        \"What is GPT?\",\n",
    "        \"What is machine learning?\"\n",
    "    ],\n",
    "    \"answers\": [\n",
    "        \"AI is the simulation of human intelligence in machines.\",\n",
    "        \"Pinecone is a vector database that enables efficient search and retrieval.\",\n",
    "        \"Embeddings are a numerical representation of text that captures semantic meaning.\",\n",
    "        \"GPT is a transformer-based model that generates human-like text.\",\n",
    "        \"Machine learning is a subset of AI where machines learn from data to make decisions.\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6229cc64-1bef-4567-8df8-7760010f8bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is AI?</td>\n",
       "      <td>AI is the simulation of human intelligence in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Pinecone?</td>\n",
       "      <td>Pinecone is a vector database that enables eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do embeddings work?</td>\n",
       "      <td>Embeddings are a numerical representation of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is GPT?</td>\n",
       "      <td>GPT is a transformer-based model that generate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is machine learning?</td>\n",
       "      <td>Machine learning is a subset of AI where machi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   questions  \\\n",
       "0                What is AI?   \n",
       "1          What is Pinecone?   \n",
       "2    How do embeddings work?   \n",
       "3               What is GPT?   \n",
       "4  What is machine learning?   \n",
       "\n",
       "                                             answers  \n",
       "0  AI is the simulation of human intelligence in ...  \n",
       "1  Pinecone is a vector database that enables eff...  \n",
       "2  Embeddings are a numerical representation of t...  \n",
       "3  GPT is a transformer-based model that generate...  \n",
       "4  Machine learning is a subset of AI where machi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b0a68a5-6509-42be-a5aa-d6a586c2d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get OpenAI embeddings\n",
    "def get_embeddings(text):\n",
    "    response = openai_client.embeddings.create(input=[text], model=\"text-embedding-ada-002\")\n",
    "    return response.data[0].embedding  # Correctly access the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db92053b-052c-4c7f-a2dd-9bcc07cdf3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Pinecone\n",
    "def insert_data_to_pinecone(df):\n",
    "    vectors = []\n",
    "    for idx, row in df.iterrows():\n",
    "        # Get the embedding for the answer text using OpenAI API\n",
    "        response = openai_client.embeddings.create(input=[row['answers']], model=\"text-embedding-ada-002\")\n",
    "        embedding = response.data[0].embedding\n",
    "        \n",
    "        \n",
    "        embedding_list = list(embedding)  # Explicitly convert to a list\n",
    "        #print(embedding_list)\n",
    "        vectors.append((str(idx), embedding_list, {'text': row['answers']}))  \n",
    "    \n",
    "    # Upsert data to Pinecone\n",
    "    index.upsert(vectors=vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0db69697-87a5-4c30-a312-edb4677bece2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 5}},\n",
       " 'total_vector_count': 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_data_to_pinecone(df)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9436762f-fcf3-4077-b110-0a3d1e60377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve the most similar document from Pinecone\n",
    "def retrieve_relevant_documents(query, top_k=3):\n",
    "    query_embedding = get_embeddings(query)\n",
    "    \n",
    "    # Ensure the query embedding is a list of floats (not ndarray)\n",
    "    query_embedding = list(query_embedding)  # Convert to list if necessary\n",
    "    \n",
    "    # Query Pinecone using the correct keyword arguments\n",
    "    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
    "    return results['matches']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf3569a5-6245-4c42-a685-217483f1b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a rich response using GPT-3 based on retrieved documents\n",
    "def generate_answer(query):\n",
    "    # Step 1: Retrieve relevant documents from Pinecone\n",
    "    matches = retrieve_relevant_documents(query)\n",
    "    \n",
    "    \n",
    "    context = \"\\n\".join([match['metadata'].get('text', 'No text found') for match in matches])\n",
    "    \n",
    "    \n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Here are some documents related to your question:\\n{context}\\n\\nQuestion: {query}\"},\n",
    "    ]\n",
    "    print(messages)\n",
    "    # Step 4: Use GPT-3.5-turbo to generate a response based on the context and question\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",  \n",
    "        messages=messages,      \n",
    "        max_tokens=500,\n",
    "        temperature=0.7        \n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2ca46c1-3a9b-4543-823c-853bcbf994ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Here are some documents related to your question:\\nMachine learning is a subset of AI where machines learn from data to make decisions.\\nAI is the simulation of human intelligence in machines.\\nGPT is a transformer-based model that generates human-like text.\\n\\nQuestion: What is machine learning - please explain in 300 words'}]\n",
      "Question: What is machine learning - please explain in 300 words\n",
      "Answer: Machine learning (ML) is a branch of artificial intelligence (AI) focused on building systems that learn and improve from experience without being explicitly programmed. The essence of machine learning revolves around developing algorithms that can process input data and use statistical analysis to predict an output while updating outputs as new data becomes available. The processes involve recognizing patterns in data and making decisions with minimal human intervention.\n",
      "\n",
      "The foundation of machine learning lies in mathematical models that mimic the way humans learn, gradually improving their accuracy by adjusting the parameters of these models based on the feedback from their performance. These models are trained using large sets of data, which provide the necessary information for them to learn and make predictions or decisions. The training process continues until the model achieves a desired level of accuracy on the provided data.\n",
      "\n",
      "Machine learning can be categorized into three primary types: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning occurs when the model is given labeled data (data with known outcomes), and the goal is to map input data to known outputs. Unsupervised learning, on the other hand, deals with unlabeled data, and the model tries to identify underlying patterns and structures in the data. Reinforcement learning is a type of learning where an agent learns to behave in an environment by performing actions and seeing the results, which typically involve rewards or penalties.\n",
      "\n",
      "Applications of machine learning are vast and impact various sectors including healthcare, finance, retail, and more. In healthcare, ML models are used for disease detection and personalized medicine. In finance, they are employed for credit scoring and algorithmic trading. In retail, machine learning improves customer experience with personalized recommendations.\n",
      "\n",
      "Overall, machine learning represents a significant advancement in the way that computers can process information, offering a more automated and intelligent approach to decision-making based on data. This technology continues to evolve, pushing boundaries of what machines can do and playing a crucial role in the advancement of artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG system\n",
    "query = \"What is machine learning - please explain in 300 words\"\n",
    "answer = generate_answer(query)\n",
    "print(f\"Question: {query}\\nAnswer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37fe9e-da87-407d-8de1-7131c87ffc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
